{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI Calculator\n\nThis notebook explains my AI Calculator project. The AI Calculator uses machine learning models to perform basic arithmetic operations: addition, subtraction, multiplication, and division. The project uses LightGBM for multiplication and division operations, and SDCA for addition and subtraction operations.\n\n## 1. Introduction\n\nThe AI Calculator project aims to demonstrate the use of machine learning algorithms to perform arithmetic operations. The models are trained to predict the results of these operations based on input data.\n\n## 2. Data\n\nThe data used for training the models consists of pairs of numbers and their corresponding arithmetic results. For example, for addition, the data looks like:\n\n| value1 | value2 | result |\n|----------|----------|-----------------|\n| 1        | 2        | 3               |\n| 3        | 5        | 8               |\n\nSimilar datasets are created for subtraction, multiplication, and division.\n\n## 3. Models\n\n### Addition and Subtraction\n\nFor addition and subtraction, we use the Stochastic Dual Coordinate Ascent (SDCA) algorithm. This algorithm is efficient for linear models and works well for these types of operations.\n\n### Multiplication and Division\n\nFor multiplication and division, we use LightGBM, a gradient boosting framework that uses tree-based learning algorithms. LightGBM is known for its efficiency and accuracy with large datasets and complex patterns.\n\n## 4. Implementation\n\n### Addition\n\nBelow is an example of how to train a model for addition using Python.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Generate synthetic data for addition\nX = np.random.randint(0, 100, (1000, 2))\ny = X[:, 0] + X[:, 1]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the model\nmodel = SGDRegressor()\nmodel.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error for Addition: {mse}')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Subtraction\n\nBelow is an example of how to train a model for subtraction using Python.\n","metadata":{}},{"cell_type":"code","source":"# Generate synthetic data for subtraction\ny = X[:, 0] - X[:, 1]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the model\nmodel = SGDRegressor()\nmodel.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error for Subtraction: {mse}')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multiplication\n\nBelow is an example of how to train a model for multiplication using Python.\n","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n\n# Generate synthetic data for multiplication\ny = X[:, 0] * X[:, 1]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create the LightGBM dataset\ntrain_data = lgb.Dataset(X_train, label=y_train)\ntest_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n\n# Set the parameters for LightGBM\nparams = {\n    'objective': 'regression',\n    'metric': 'mse',\n    'boosting_type': 'gbdt',\n    'verbosity': -1\n}\n\n# Train the model\nmodel = lgb.train(params, train_data, valid_sets=[test_data], early_stopping_rounds=10)\n\n# Predict on the test set\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error for Multiplication: {mse}')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Division\n\nBelow is an example of how to train a model for division using Python.\n","metadata":{}},{"cell_type":"code","source":"# Generate synthetic data for division\nX = np.random.randint(1, 100, (1000, 2))  # Avoid division by zero\ny = X[:, 0] / X[:, 1]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create the LightGBM dataset\ntrain_data = lgb.Dataset(X_train, label=y_train)\ntest_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n\n# Set the parameters for LightGBM\nparams = {\n    'objective': 'regression',\n    'metric': 'mse',\n    'boosting_type': 'gbdt',\n    'verbosity': -1\n}\n\n# Train the model\nmodel = lgb.train(params, train_data, valid_sets=[test_data], early_stopping_rounds=10)\n\n# Predict on the test set\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error for Division: {mse}')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The source code for this project can be found at [AI Calculator by Brainydaps](http://https://github.com/Brainydaps/AICalculator)","metadata":{}}]}